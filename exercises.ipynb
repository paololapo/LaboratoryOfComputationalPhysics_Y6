{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The MickeyMouse problem\n",
    "\n",
    "a) Write a program that prints the numbers from 1 to 100. But for multiples of 3 print `Mickey` instead of the corresponding number and for the multiples of 5 print `Mouse`. For numbers which are multiples of both three and five print `MickeyMouse`\n",
    "\n",
    "b) Put the result in a tuple and substitute `Mickey` with `Donald` and `Mouse` with `Duck`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. The swap function\n",
    "\n",
    "Write a function that swap the values of two input variables x and y (whatever the type). Try to do that also without a temporary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Computing the distance\n",
    "\n",
    "Write a function that calculates and returns the euclidean distance between two points *u* and *v*, where *u* and *v* are both 2-tuples *(x,y)*. For example, if *u=(3,0)* and *v=(0,4)*, the function should return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Counting letters\n",
    "\n",
    "Write a program to calculate the number of times each character occurs in a given string *s*. Ignore differneces in capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Isolating the unique\n",
    "\n",
    "Write a function that determines and count the unique numbers in the list *l*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Combination of functions\n",
    "\n",
    "Write two functions - one that returns the square of a number, and one that returns the cube. Now write a third function that returns the number raised to the 6th power using the two previous functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Cubes\n",
    "\n",
    "Create a list of the cubes of x for x in *[0, 10]* using:\n",
    "\n",
    "a) a for loop\n",
    "\n",
    "b) a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Nested list comprehension\n",
    "\n",
    "A Pythagorean triple is an integer solution to the Pythagorean theorem $a^2+b^2=c^2$. The first Pythagorean triple is (3,4,5). Find and put in a tuple all unique Pythagorean triples for the positive integers a, b and c less than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Normalization\n",
    "\n",
    "Write a function that takes a tuple of numbers and returns it with the entries normalized to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0\\. Implement a function (whatever you want) and save it to a file (e.g. `function.py`). Import that file and use that function in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Write the following as a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Convert the following function into a pure function with no global variables or side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Write a `decorator` hello that makes every wrapped function print “Hello!”, i.e. something like:\n",
    "\n",
    "```python\n",
    "@hello\n",
    "def square(x):\n",
    "    return x*x\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Write the factorial function so that it a) does and b) does not use recursion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Use HOFs (zip in particular) to compute the weight of a circle, a disk and a sphere, assuming different radii and different densities:\n",
    "\n",
    "```python\n",
    "densities = {\"Al\":[0.5,1,2],\"Fe\":[3,4,5],\"Pb\": [15,20,30]}\n",
    "radii = [1,2,3]\n",
    "```\n",
    "\n",
    "where the entries of the dictionary's values are the linear, superficial and volumetric densities of the materials respectively.\n",
    "\n",
    "In particular define a list of three lambda functions using a comprehension that computes the circumference, the area and the volume for a given radius.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Edit the class defintion to add an instance attribute of is_hungry = True to the Dog class. Then add a method called eat() which changes the value of is_hungry to False when called. Figure out the best way to feed each dog and then output “My dogs are hungry.” if all are hungry or “My dogs are not hungry.” if all are not hungry. The final output should look like this:\n",
    "\n",
    "`I have 3 dogs. \n",
    "Tom is 6. \n",
    "Fletcher is 7. \n",
    "Larry is 9. \n",
    "And they're all mammals, of course. \n",
    "My dogs are not hungry.\n",
    "`\n",
    "\n",
    "```python\n",
    "# Parent class\n",
    "class Dog:\n",
    "\n",
    "    # Class attribute\n",
    "    species = 'mammal'\n",
    "\n",
    "    # Initializer / Instance attributes\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    # instance method\n",
    "    def description(self):\n",
    "        return \"{} is {} years old\".format(self.name, self.age)\n",
    "\n",
    "    # instance method\n",
    "    def speak(self, sound):\n",
    "        return \"{} says {}\".format(self.name, sound)\n",
    "\n",
    "# Child class (inherits from Dog class)\n",
    "class RussellTerrier(Dog):\n",
    "    def run(self, speed):\n",
    "        return \"{} runs {}\".format(self.name, speed)\n",
    "\n",
    "# Child class (inherits from Dog class)\n",
    "class Bulldog(Dog):\n",
    "    def run(self, speed):\n",
    "        return \"{} runs {}\".format(self.name, speed)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number rappresentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Write a function that converts number representation, bin<->dec<->hex. (Clearly using the corresponding python built-in functions is not fair..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a function that converts a 32 bit word into a single precision floating point (i.e. interprets the various bits as sign, mantissa and exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Write a program to determine the underflow and overflow limits (within a factor of 2) for python on your computer. \n",
    "\n",
    "**Tips**: define two variables inizialized to 1 and halve/double them enough time to exceed the under/over-flow limits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Write a program to determine the machine precision\n",
    "\n",
    "**Tips**: define a new variable by adding a smaller and smaller value (proceeding similarly to prob. 2) to an original variable and check the point where the two are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Write a function that takes in input three parameters $a$, $b$ and $c$ and prints out the two solutions to the quadratic equation $ax^2+bx+c=0$ using the standard formula:\n",
    "$$\n",
    "x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\n",
    "$$\n",
    "\n",
    "(a) use the program to compute the solution for $a=0.001$, $b=1000$ and $c=0.001$\n",
    "\n",
    "(b) re-express the standard solution formula by multiplying top and bottom by $-b\\mp\\sqrt{b^2-4ac}$ and again find the solution for $a=0.001$, $b=1000$ and $c=0.001$. How does it compare with what previously obtained? Why?\n",
    "\n",
    "(c) write a function that compute the roots of a quadratic equation accurately in all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Write a program that implements the function $f(x)=x(x−1)$\n",
    "\n",
    "(a) Calculate the derivative of the function at the point $x = 1$ using the derivative definition:\n",
    "\n",
    "$$\n",
    "\\frac{{\\rm d}f}{{\\rm d}x} = \\lim_{\\delta\\to0} \\frac{f(x+\\delta)-f(x)}{\\delta}\n",
    "$$\n",
    "\n",
    "with $\\delta = 10^{−2}$. Calculate the true value of the same derivative analytically and compare with the answer your program gives. The two will not agree perfectly. Why not?\n",
    "\n",
    "(b) Repeat the calculation for $\\delta = 10^{−4}, 10^{−6}, 10^{−8}, 10^{−10}, 10^{−12}$ and $10^{−14}$. How does the accuracy scales with $\\delta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Consider the integral of the semicircle of radius 1:\n",
    "$$\n",
    "I=\\int_{-1}^{1} \\sqrt(1-x^2) {\\rm d}x\n",
    "$$\n",
    "which it's known to be $I=\\frac{\\pi}{2}=1.57079632679...$.\n",
    "Alternatively we can use the Riemann definition of the integral:\n",
    "$$\n",
    "I=\\lim_{N\\to\\infty} \\sum_{k=1}^{N} h y_k \n",
    "$$\n",
    "\n",
    "with $h=2/N$ the width of each of the $N$ slices the domain is divided into and where\n",
    "$y_k$ is the value of the function at the $k-$th slice.\n",
    "\n",
    "(a) Write a programe to compute the integral with $N=100$. How does the result compares to the true value?\n",
    "\n",
    "(b) How much can $N$ be increased if the computation needs to be run in less than a second? What is the gain in running it for 1 minute? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\.a Make a new directory called `students` in your home. Download a csv file with the list of students of this lab from [here](https://www.dropbox.com/s/867rtx3az6e9gm8/LCP_22-23_students.csv) (use the `wget` command) and copy that to `students`. First check whether the file is already there\n",
    "\n",
    "1\\.b Make two new files, one containing the students belonging to PoD, the other to Physics.\n",
    "\n",
    "1\\.c For each letter of the alphabet, count the number of students whose surname starts with that letter. \n",
    "\n",
    "1\\.d Find out which is the letter with most counts.\n",
    "\n",
    "1\\.e Assume an obvious numbering of the students in the file (first line is 1, second line is 2, etc.), group students \"modulo 18\", i.e. 1,19,37,.. 2,20,38,.. etc. and put each group in a separate file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a Make a copy of the file `data.csv` removing the metadata and the commas between numbers; call it `data.txt`\n",
    "\n",
    "2\\.b How many even numbers are there?\n",
    "\n",
    "2\\.c Distinguish the entries on the basis of `sqrt(X^2 + Y^2 + Z^2)` is greater or smaller than `100*sqrt(3)/2`. Count the entries of each of the two groups \n",
    "\n",
    "2\\.d Make `n` copies of data.txt (with `n` an input parameter of the script), where the i-th copy has all the numbers divided by i (with `1<=i<=n`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Find the row, column and overall means for the following matrix:\n",
    "```python\n",
    "m = np.arange(12).reshape((3,4))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Find the outer product of the following two vecotrs\n",
    "\n",
    "```python\n",
    "u = np.array([1,3,5,7])\n",
    "v = np.array([2,4,6,8])\n",
    "```\n",
    "\n",
    "Do this in the following ways:\n",
    "\n",
    "   * Using the function outer in numpy\n",
    "   * Using a nested for loop or list comprehension\n",
    "   * Using numpy broadcasting operatoins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Create a 10 by 6 matrix of random uniform numbers. Set all rows with any entry less than 0.1 to be zero\n",
    "\n",
    "Hint: Use the following numpy functions - np.random.random, np.any as well as Boolean indexing and the axis argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Use np.linspace to create an array of 100 numbers between 0 and 2π (includsive).\n",
    "\n",
    "  * Extract every 10th element using slice notation\n",
    "  * Reverse the array using slice notation\n",
    "  * Extract elements where the absolute difference between the sine and cosine functions evaluated at that element is less than 0.1\n",
    "  * Make a plot showing the sin and cos functions and indicate where they are close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Create a matrix that shows the 10 by 10 multiplication table.\n",
    "\n",
    " * Find the trace of the matrix\n",
    " * Extract the anto-diagonal (this should be ```array([10, 18, 24, 28, 30, 30, 28, 24, 18, 10])```)\n",
    " * Extract the diagnoal offset by 1 upwards (this should be ```array([ 2,  6, 12, 20, 30, 42, 56, 72, 90])```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Use broadcasting to create a grid of distances\n",
    "\n",
    "Route 66 crosses the following cities in the US: Chicago, Springfield, Saint-Louis, Tulsa, Oklahoma City, Amarillo, Santa Fe, Albuquerque, Flagstaff, Los Angeles\n",
    "The corresponding positions in miles are: 0, 198, 303, 736, 871, 1175, 1475, 1544, 1913, 2448\n",
    "\n",
    "  * Construct a 2D grid of distances among each city along Route 66\n",
    "  * Convert that in km (those savages...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Prime numbers sieve: compute the prime numbers in the 0-N (N=99 to start with) range with a sieve (mask).\n",
    "  * Constract a shape (100,) boolean array, the mask\n",
    "  * Identify the multiples of each number starting from 2 and set accordingly the corresponding mask element\n",
    "  * Apply the mask to obtain an array of ordered prime numbers\n",
    "  * Check the performances (timeit); how does it scale with N?\n",
    "  * Implement the optimization suggested in the [sieve of Eratosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Diffusion using random walk\n",
    "\n",
    "Consider a simple random walk process: at each step in time, a walker jumps right or left (+1 or -1) with equal probability. The goal is to find the typical distance from the origin of a random walker after a given amount of time. \n",
    "To do that, let's simulate many walkers and create a 2D array with each walker as a raw and the actual time evolution as columns\n",
    "\n",
    "  * Take 1000 walkers and let them walk for 200 steps\n",
    "  * Use randint to create a 2D array of size walkers x steps with values -1 or 1\n",
    "  * Build the actual walking distances for each walker (i.e. another 2D array \"summing on each raw\")\n",
    "  * Take the square of that 2D array (elementwise)\n",
    "  * Compute the mean of the squared distances at each step (i.e. the mean along the columns)\n",
    "  * Plot the average distances (sqrt(distance\\*\\*2)) as a function of time (step)\n",
    "  \n",
    "Did you get what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Analyze a data file \n",
    "  * Download the population of hares, lynxes and carrots at the beginning of the last century.\n",
    "    ```python\n",
    "    ! wget https://www.dropbox.com/s/3vigxoqayo389uc/populations.txt\n",
    "    ```\n",
    "\n",
    "  * Check the content by looking within the file\n",
    "  * Load the data (use an appropriate numpy method) into a 2D array\n",
    "  * Create arrays out of the columns, the arrays being (in order): *year*, *hares*, *lynxes*, *carrots* \n",
    "  * Plot the 3 populations over the years\n",
    "  * Compute the main statistical properties of the dataset (mean, std, correlations, etc.)\n",
    "  * Which species has the highest population each year?\n",
    "\n",
    "Do you feel there is some evident correlation here? [Studies](https://www.enr.gov.nt.ca/en/services/lynx/lynx-snowshoe-hare-cycle) tend to believe so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. OSEMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a random list of number and then save it to a text file named \"simple_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Create a random matrix of 5x5 and then save it to a text file named \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the saved txt file of point 2 and convert it to a csv file (by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. load the binary file named *credit_card.dat* and convert the data into the real credit-card number.\n",
    "Each line correspond to a credit card number.\n",
    "Each character is composed by 6 bit (even the space) and the last 4 bit are just a padding\n",
    "\n",
    "**hint**: use the `chr()` function to convert a number to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Load the file \"user_data.json\", filter the data by the \"CreditCardType\" field equals to \"American Express\". Than save the data a to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Load the file from this url: [https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1](https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1) with Pandas. \n",
    "+ Explore the data (see the info of the data)\n",
    "+ Draw the istogram of the 'class' field. Decribe wath yuou see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Load the remote file [https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1](https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1) with Pandas and plot a scatter plot all possible combination of the following fields:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Load the same file of point 6, and convert the file to json with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pandas\n",
    "\n",
    "This exercise consists in analyzing a dataset containg timing information from a series of Time-to-Digital-Converters (TDC) implemented in a couple of FPGAs. Each measurement (i.e. each row of the input file) consists of a flag that specifies the type of message ('HEAD', which in this case is always 1), two addresses of the TDC providing the signal ('FPGA' and 'TDC_CHANNEL'), and the timing information ('ORBIT_CNT', 'BX_COUNTER', and 'TDC_MEAS'). Each TDC count corresponds to 25/30 ns, whereas a unit of BX_COUNTER corresponds to 25 ns, and the ORBIT_CNT is increased every 'x' BX_COUNTER. This allows to store the time in a similar way to hours, minutes and seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you didn't download it yet, please get the relevant file now!\n",
    "!wget https://www.dropbox.com/s/xvjzaxzz3ysphme/data_000637.txt -P ~/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a Pandas DataFrame reading N rows of the 'data_000637.txt' dataset. Choose N to be smaller than or equal to the maximum number of rows and larger that 10k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Find out the number of BX in a ORBIT (the value 'x').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Find out how much the data taking lasted. You can either make an estimate based on the fraction of the measurements (rows) you read, or perform this check precisely by reading out the whole dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Create a new column with the absolute time in ns (as a combination of the other three columns with timing information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Replace the values (all 1) of the HEAD column randomly with 0 or 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Create a new DataFrame that contains only the rows with HEAD=1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Make two occupancy plots (one for each FPGA), i.e. plot the number of counts per TDC channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Use the groupby method to find out the noisy channels, i.e. the TDC channels with most counts (say the top 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Count the number of unique orbits. Count the number of unique orbits with at least one measurement from TDC_CHANNEL=139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Kernel Density Estimate**\n",
    "\n",
    "Produce a KDE for a given distribution (by hand, not using seaborn!):\n",
    "\n",
    "* Fill a numpy array, x,  of len(N) (with N=O(100)) with a variable normally distributed, with a given mean a standard deviation\n",
    "* Fill an histogram in pyplot taking properly care about the aesthetic\n",
    "   * use a meaningful number of bins\n",
    "   * set a proper y axis label\n",
    "   * set proper value of y axis major ticks labels (e.g. you want to display only integer labels)\n",
    "   * display the histograms as data points with errors (the error being the poisson uncertainty)\n",
    "* for every element of x, create a gaussian with the mean corresponding the element value and std as a parameter that can be tuned. The std default value should be:\n",
    "$$ 1.06 * x.std() * x.size ^{-\\frac{1}{5.}} $$\n",
    "you can use the scipy function `stats.norm()` for that.\n",
    "* In a separate plot (to be placed beside the original histogram), plot all the gaussian functions so obtained\n",
    "* Sum (with np.sum()) all the gaussian functions and normalize the result such that the integral matches the integral of the original histogram. For that you could use the `scipy.integrate.trapz()` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Color-coded scatter plot**\n",
    "\n",
    "Produce a scatter plot out of a dataset with two categories\n",
    "\n",
    "* Write a function that generate a 2D datasets of 2 categories. Each category should distribute as a 2D gaussian with a given mean and std (clearly it is better to have different values means..)\n",
    "* Display the dataset in a scatter plot marking the two categories with different marker colors.\n",
    "\n",
    "An example is given below\n",
    "\n",
    "You can try to make the procedure more general by allowing a given number $n\\ge 2$ of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://www.dropbox.com/s/u4y3k4kk5tc7j46/two_categories_scatter_plot.png\n",
    "from IPython.display import Image\n",
    "Image('two_categories_scatter_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Profile plot**\n",
    "\n",
    "Produce a profile plot from a scatter plot.\n",
    "* Download the following dataset and load it as a pandas dataframe:\n",
    "```bash\n",
    "wget https://www.dropbox.com/s/hgnvyj9abatk8g6/residuals_261.npy\n",
    "```\n",
    "Note that you should use the `np.load()` function to load the file as a numpy array, call the `.item()` method, and then pass it to the `pd.DataFrame()` constructor.\n",
    "* Inspect the dataset, you'll find two variables (features)\n",
    "* Clean the sample by selecting the entries (rows) with the variable \"residual\" in absolute value smaller than 2\n",
    "* perform a linear regression of \"residuals\" versus \"distances\" using `scipy.stats.linregress()` \n",
    "* plot a seaborn jointplot of  \"residuals\" versus \"distances\", having seaborn performing a linear regression. The result of the regression should be displayed on the plot\n",
    "* Fill 3 numpy arrays\n",
    "  * x, serving as an array of bin centers for the \"distance\" variable. It should range from 0 to 20 with reasonable number of steps (bins)\n",
    "  * y, the mean values of the \"residuals\", estimated in slices (bins) of \"distance\"\n",
    "  * erry, the standard deviation of the  of the \"residuals\", estimated in slices (bins) of \"distance\"\n",
    "* Plot the profile plot on top of the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **PCA on 3D dataset**\n",
    "\n",
    "* Generate a dataset with 3 features each with N entries (N being ${\\cal O}(1000)$). With $N(\\mu,\\sigma)$ the normali distribution with mean $\\mu$ and $\\sigma$  standard deviation, generate the 3 variables $x_{1,2,3}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$\n",
    "* Find the eigenvectors and eigenvalues of the covariance matrix of the dataset\n",
    "* Find the eigenvectors and eigenvalues using SVD. Check that the two procedures yield to same result\n",
    "* What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained.\n",
    "* Redefine the data in the basis yielded by the PCA procedure\n",
    "* Plot the data points in the original and the new coordiantes as a set of scatter plots. Your final figure should have 2 rows of 3 plots each, where the columns show the (0,1), (0,2) and (1,2) proejctions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **PCA on a nD dataset**\n",
    "\n",
    "Start from the dataset you have genereted in the previous exercise and add uncorrelated random noise. Such noise should be represented by other 10 uncorrelated variables normal distributed, with standar deviation much smaller (say, a factor 50) than those used to generate the $x_1$ and $x_2$.\n",
    "\n",
    "Repeat the PCA procedure and compare the results with what you obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 \\. **Looking at an oscillating spring** (optional)\n",
    "\n",
    "Imagine you have $n$ cameras looking at a spring oscillating along the $x$ axis. Each  camera record the motion of the spring looking at it along a given direction defined by the pair $(\\theta_i, \\phi_i)$, the angles in spherical coordinates. \n",
    "\n",
    "Start from the simulation of the records (say ${\\cal O}(1000)$) of the spring's motion along the x axis, assuming a little random noise affects the measurements along the $y$. Rotate such dataset to emulate the records of each camera.\n",
    "\n",
    "Perform a Principal Component Analysis on the thus obtained dataset, aiming at finding the only one coordinate that really matters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **PCA on the MAGIC dataset** (optional)\n",
    "\n",
    "Perform a PCA on the magic04.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Maximum wind speed prediction at the Sprogø station**\n",
    "\n",
    "The exercise goal is to predict the maximum wind speed occurring every 50 years even if no measure exists for such a period. The available data are only measured over 21 years at the Sprogø meteorological station located in Denmark. \n",
    "\n",
    "The annual maxima are supposed to fit a normal probability density function. However such function is not going to be estimated because it gives a probability from a wind speed maxima. Finding the maximum wind speed occurring every 50 years requires the opposite approach, the result needs to be found from a defined probability. That is the quantile function role and the exercise goal will be to find it. In the current model, it is supposed that the maximum wind speed occurring every 50 years is defined as the upper 2% quantile.\n",
    "\n",
    "By definition, the quantile function is the inverse of the cumulative distribution function. The latter describes the probability distribution of an annual maxima. In the exercise, the cumulative probability $p_i$ for a given year i is defined as $p_i = i/(N+1)$ with $N = 21$, the number of measured years. Thus it will be possible to calculate the cumulative probability of every measured wind speed maxima. From those experimental points, the scipy.interpolate module will be very useful for fitting the quantile function. Finally the 50 years maxima is going to be evaluated from the cumulative probability of the 2% quantile.\n",
    "\n",
    "Practically, load the dataset:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "max_speeds = np.load('max-speeds.npy')\n",
    "years_nb = max_speeds.shape[0]\n",
    "```\n",
    "\n",
    "Compute then the cumulative probability $p_i$ (`cprob`) and sort the maximum speeds from the data. Use then the  UnivariateSpline from scipy.interpolate to define a quantile function and thus estimate the probabilities.\n",
    "\n",
    "In the current model, the maximum wind speed occurring every 50 years is defined as the upper 2% quantile. As a result, the cumulative probability value will be:\n",
    "\n",
    "```python\n",
    "fifty_prob = 1. - 0.02\n",
    "```\n",
    "\n",
    "So the storm wind speed occurring every 50 years can be guessed as:\n",
    "\n",
    "``` python\n",
    "fifty_wind = quantile_func(fifty_prob)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Curve fitting of temperature in Alaska** \n",
    "\n",
    "The temperature extremes in Alaska for each month, starting in January, are given by (in degrees Celcius):\n",
    "\n",
    "max:  17,  19,  21,  28,  33,  38, 37,  37,  31,  23,  19,  18\n",
    "\n",
    "min: -62, -59, -56, -46, -32, -18, -9, -13, -25, -46, -52, -58\n",
    "\n",
    "* Plot these temperature extremes.\n",
    "* Define a function that can describe min and max temperatures. \n",
    "* Fit this function to the data with scipy.optimize.curve_fit().\n",
    "* Plot the result. Is the fit reasonable? If not, why?\n",
    "* Is the time offset for min and max temperatures the same within the fit accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **2D minimization of a six-hump camelback function**\n",
    "\n",
    "$$\n",
    "f(x,y) = \\left(4-2.1x^2+\\frac{x^4}{3} \\right) x^2 +xy + (4y^2 -4)y^2\n",
    "$$\n",
    "\n",
    "has multiple global and local minima. Find the global minima of this function.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* Variables can be restricted to $-2 < x < 2$ and $-1 < y < 1$.\n",
    "* Use numpy.meshgrid() and pylab.imshow() to find visually the regions.\n",
    "* Use scipy.optimize.minimize(), optionally trying out several of its methods.\n",
    "\n",
    "How many global minima are there, and what is the function value at those points? What happens for an initial guess of $(x, y) = (0, 0)$ ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **FFT of a simple dataset**\n",
    "\n",
    "Performe a periodicity analysis on the lynxs-hares population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **FFT of an image**\n",
    "\n",
    "* Examine the provided image `moonlanding.png`, which is heavily contaminated with periodic noise. In this exercise, we aim to clean up the noise using the Fast Fourier Transform.\n",
    "* Load the image using pylab.imread().\n",
    "* Find and use the 2-D FFT function in scipy.fftpack, and plot the spectrum (Fourier transform of) the image. Do you have any trouble visualising the spectrum? If so, why?\n",
    "* The spectrum consists of high and low frequency components. The noise is contained in the high-frequency part of the spectrum, so set some of those components to zero (use array slicing).\n",
    "* Apply the inverse Fourier transform to see the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
